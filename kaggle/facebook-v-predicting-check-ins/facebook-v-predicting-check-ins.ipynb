{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d47f91",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-08T02:43:33.839326Z",
     "iopub.status.busy": "2021-07-08T02:43:33.837603Z",
     "iopub.status.idle": "2021-07-08T02:43:33.851159Z",
     "shell.execute_reply": "2021-07-08T02:43:33.851653Z",
     "shell.execute_reply.started": "2021-07-08T02:40:22.850124Z"
    },
    "papermill": {
     "duration": 0.023994,
     "end_time": "2021-07-08T02:43:33.851925",
     "exception": false,
     "start_time": "2021-07-08T02:43:33.827931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/facebook-v-predicting-check-ins/train.csv.zip\n",
      "/kaggle/input/facebook-v-predicting-check-ins/sample_submission.csv.zip\n",
      "/kaggle/input/facebook-v-predicting-check-ins/test.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27c52f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T02:43:33.863627Z",
     "iopub.status.busy": "2021-07-08T02:43:33.862915Z",
     "iopub.status.idle": "2021-07-08T03:01:25.903550Z",
     "shell.execute_reply": "2021-07-08T03:01:25.902900Z"
    },
    "papermill": {
     "duration": 1072.047243,
     "end_time": "2021-07-08T03:01:25.903817",
     "exception": false,
     "start_time": "2021-07-08T02:43:33.856574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Loading train data\n",
      "Feature engineering on train\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering on test\n",
      "Data prepared in: 0:01:11.319446\n",
      "[0, 1929.3166666666668, 3843.4533333333334, 5757.59, 7671.7266666666665, 9585.863333333333, 11500.0, 13414.136666666667, 15328.273333333334, 17242.41, 19156.546666666665, 21070.68333333333, 23001.0]\n",
      "[0, 2275.3125, 4523.111413043478, 6770.910326086956, 9018.709239130434, 11266.508152173912, 13514.30706521739, 15762.105978260868, 18009.904891304348, 20257.703804347828, 22505.502717391308, 24753.301630434788, 27001.100543478267, 29248.899456521747, 31496.698369565227, 33744.4972826087, 35992.29619565218, 38240.09510869566, 40487.89402173914, 42735.69293478262, 44983.4918478261, 47231.29076086958, 49479.08967391306, 51726.88858695654, 53974.68750000002, 56251.0]\n",
      "Row 0 completed in: 0:01:21.378683\n",
      "Row 1 completed in: 0:01:20.130581\n",
      "Row 2 completed in: 0:01:25.684958\n",
      "3 3 0 cell_train.shape (54375, 11)\n",
      "Row 3 completed in: 0:01:27.816338\n",
      "Row 4 completed in: 0:01:23.149828\n",
      "Row 5 completed in: 0:01:21.228679\n",
      "Row 6 completed in: 0:01:25.098771\n",
      "Row 7 completed in: 0:01:17.441126\n",
      "Row 8 completed in: 0:01:25.665241\n",
      "Row 9 completed in: 0:01:21.024564\n",
      "Row 10 completed in: 0:01:18.060153\n",
      "Row 11 completed in: 0:01:15.374696\n",
      "Predictions made in: 0:17:33.593415\n",
      "Pred shape: (8607230, 4)\n",
      "Writing submission file\n",
      "Task completed in: 0:17:50.056619\n"
     ]
    }
   ],
   "source": [
    "'''Inspired by several scripts at:\n",
    "https://www.kaggle.com/c/facebook-v-predicting-check-ins/scripts\n",
    "Special thanks to Sandro for starting the madness. :-)\n",
    "https://www.kaggle.com/svpons/facebook-v-predicting-check-ins/grid-plus-classifier\n",
    "\n",
    "KNN accelerated V3.\n",
    "Numpy argsort replaced with faster JIT compiled function for finding \n",
    "top three predictions.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "# Found at: https://www.kaggle.com/rshekhar2/facebook-v-predicting-check-ins/xgboost-cv-example-with-small-bug\n",
    "def mapkprecision(truthvalues, predictions):\n",
    "    '''\n",
    "    This is a faster implementation of MAP@k valid for numpy arrays.\n",
    "    It is only valid when there is one single truth value. \n",
    "\n",
    "    m ~ number of observations\n",
    "    k ~ MAP at k -- in this case k should equal 3\n",
    "\n",
    "    truthvalues.shape = (m,) \n",
    "    predictions.shape = (m, k)\n",
    "    '''\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return np.mean(np.sum(z, axis=1))\n",
    "\n",
    "def load_data(data_name):\n",
    "    types = {'row_id': np.dtype(np.int32),\n",
    "         'x': np.dtype(float),\n",
    "         'y' : np.dtype(float),\n",
    "         'accuracy': np.dtype(np.int16),\n",
    "         'place_id': np.int64,\n",
    "         'time': np.dtype(np.int32)}\n",
    "    df = pd.read_csv(data_name, dtype=types, na_filter=False)\n",
    "    return df\n",
    "\n",
    "def process_one_cell(cell_train, cell_test, fw, th, n_neighbors):\n",
    "    \n",
    "    # Remove infrequent places\n",
    "    places, idx, counts = np.unique(cell_train[:, -1], return_inverse=True, \n",
    "                                    return_counts=True)\n",
    "    count_per_row = counts[idx]\n",
    "    cell_train = cell_train[count_per_row >= th]\n",
    "\n",
    "    # Store row_ids for test\n",
    "    row_ids = cell_test[:, -1].flatten().astype(np.int32)\n",
    "    cell_test = cell_test[:, :-1]\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred, classes = get_preds(cell_train, cell_test, n_neighbors)\n",
    "    \n",
    "    # Get top three predictions\n",
    "    y_pred_labels = top_three_preds(y_pred)\n",
    "    pred_labels = classes[y_pred_labels]\n",
    "    cell_pred = np.column_stack((row_ids, pred_labels)).astype(np.int64) \n",
    "    \n",
    "    return cell_pred\n",
    "    \n",
    "def get_preds(cell_train, cell_test, n_neighbors):\n",
    "    # Preparing data\n",
    "    y = cell_train[:, -1].flatten().astype(np.int64)\n",
    "    X = cell_train[:, :-1]\n",
    "    X_test = cell_test\n",
    "    \n",
    "    #Applying the classifier\n",
    "    cte = 5.9\n",
    "    n_neighbors = int((y.size ** 0.5) / cte)\n",
    "    leaf_size = int(n_neighbors ** 0.5 * 2.68)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                            weights=calculate_distance, p=1,\n",
    "                            n_jobs=2, leaf_size=leaf_size)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    return y_pred, clf.classes_\n",
    "    \n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2.37\n",
    "    \n",
    "# Faster than argsort at getting top three predictions\n",
    "@jit(nopython=True)\n",
    "def top_three_preds(preds):\n",
    "    place_count = preds.shape[0]\n",
    "    preds_count = preds.shape[1]\n",
    "    pred_labels = np.zeros((place_count, 3), dtype=np.int32)\n",
    "    for i in range(place_count):\n",
    "        first_place_score = 0\n",
    "        second_place_score = 0\n",
    "        third_place_score = 0\n",
    "        for j in range(preds_count):\n",
    "            this_pred = preds[i,j]\n",
    "            if (this_pred > 0) and (this_pred > third_place_score):\n",
    "                if this_pred > second_place_score:\n",
    "                    pred_labels[i, 2] = pred_labels[i, 1]\n",
    "                    third_place_score = second_place_score\n",
    "                    if this_pred > first_place_score:\n",
    "                        pred_labels[i, 1] = pred_labels[i, 0]\n",
    "                        second_place_score = first_place_score\n",
    "                        first_place_score = this_pred\n",
    "                        pred_labels[i, 0] = j\n",
    "                    else:\n",
    "                        second_place_score = this_pred\n",
    "                        pred_labels[i, 1] = j\n",
    "                else:\n",
    "                    third_place_score = this_pred\n",
    "                    pred_labels[i, 2] = j\n",
    "    return pred_labels\n",
    "    \n",
    "# Precompute the trig values\n",
    "def time_trig(max_time):\n",
    "    time_array = np.linspace(0, 2*np.pi, max_time)\n",
    "    sin_values = np.sin(time_array)\n",
    "    cos_values = np.cos(time_array)\n",
    "    return (sin_values, cos_values)\n",
    "    \n",
    "# Generate a dictionary of the time limits so it doesn't have to be \n",
    "# recalculated each loop\n",
    "def create_time_dict(t_cuts, time_mod, time_weight, time_aug):\n",
    "    \n",
    "    t_slice = 24 / t_cuts\n",
    "    time_dict = dict()\n",
    "    trig_array = time_trig(time_mod)\n",
    "    for t in range(t_cuts):\n",
    "        \n",
    "        t_min = int(t * t_slice * 12)\n",
    "        t_max = int((t + 1) * t_slice * 12 - 1)\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop))\n",
    "        time_dict[t] = [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "\n",
    "        t_min = int((t * t_slice - time_aug) * 12)%time_mod\n",
    "        t_max = int(((t + 1) * t_slice + time_aug)* 12 - 1)%time_mod\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop, sin_t_min))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop, sin_t_max))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop, cos_t_min))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop, cos_t_max))\n",
    "        time_dict[t] += [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        \n",
    "    return time_dict\n",
    "\n",
    "@jit\n",
    "def apply_mask(data, feature, mask_min, mask_max):\n",
    "    mask = (data[:, feature] >= mask_min)\n",
    "    mask = mask & (data[:, feature] < mask_max)      \n",
    "    return data[mask]    \n",
    "\n",
    "def process_grid(train, test, x_cut_list, y_cut_list, t_cuts,\n",
    "                 x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors):\n",
    "    preds_list = []\n",
    "    x_cuts = len(x_cut_list) - 1\n",
    "    y_cuts = len(y_cut_list) - 1\n",
    "    time_mod = 288\n",
    "    time_weight = fw[2]\n",
    "    time_dict = create_time_dict(t_cuts, time_mod, time_weight, time_aug)\n",
    "\n",
    "    for i in range(x_cuts):\n",
    "        row_start_time = time.time()\n",
    "        x_min = x_cut_list[i]\n",
    "        x_max = x_cut_list[i+1]\n",
    "        #x_max += int((i+1) == x_cuts) # expand edge at end\n",
    "\n",
    "        col_test = apply_mask(test, 0, x_min, x_max)\n",
    "        x_min -= x_border_aug\n",
    "        x_max += x_border_aug\n",
    "        col_train = apply_mask(train, 0, x_min, x_max)\n",
    "\n",
    "        for j in range(y_cuts):\n",
    "            y_min = y_cut_list[j]\n",
    "            y_max = y_cut_list[j+1]\n",
    "            #y_max += int((j+1) == y_cuts) # expand edge at end\n",
    "\n",
    "            row_test = apply_mask(col_test, 1, y_min, y_max)\n",
    "            y_min -= y_border_aug\n",
    "            y_max += y_border_aug\n",
    "            row_train = apply_mask(col_train, 1, y_min, y_max)\n",
    "\n",
    "            for t in range(t_cuts):\n",
    "                #print(df_row_test.shape, df_row_train.shape)\n",
    "                t_lim = time_dict[t]\n",
    "                mask = (row_test[:, 2] >= t_lim[0])\n",
    "                mask = mask & (row_test[:, 2] <= t_lim[1])\n",
    "                mask = mask & (row_test[:, 3] >= t_lim[2])\n",
    "                mask = mask & (row_test[:, 3] <= t_lim[3])\n",
    "                cell_test = row_test[mask]\n",
    "                mask = (row_train[:, 2] >= t_lim[4])\n",
    "                mask = mask & (row_train[:, 2] <= t_lim[5])\n",
    "                mask = mask & (row_train[:, 3] >= t_lim[6])\n",
    "                mask = mask & (row_train[:, 3] <= t_lim[7])\n",
    "                cell_train = row_train[mask]\n",
    "                #print('cell_train.shape', cell_train.shape)\n",
    "                if i==3 and j==3 and t==0:\n",
    "                    print(i, j, t, 'cell_train.shape', cell_train.shape)\n",
    "                    \n",
    "                cell_pred = process_one_cell(cell_train, cell_test, \n",
    "                                             fw, th, n_neighbors)\n",
    "                preds_list.append(cell_pred)\n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    preds = np.vstack(preds_list)\n",
    "    return preds\n",
    "\n",
    "# Thank you Alex!\n",
    "# From: https://www.kaggle.com/drarfc/facebook-v-predicting-check-ins/fastest-way-to-write-the-csv\n",
    "def generate_submission(preds):    \n",
    "    print('Writing submission file')\n",
    "    with open('KNN_submission.csv', \"w\") as out:\n",
    "        out.write(\"row_id,place_id\\n\")\n",
    "        rows = ['']*8607230\n",
    "        n=0\n",
    "        for num in range(8607230):\n",
    "            rows[n]='%d,%d %d %d\\n' % (preds[num,0],preds[num,1],preds[num,2],preds[num,3])\n",
    "            n=n+1\n",
    "        out.writelines(rows)\n",
    "\n",
    "def validation_split(df, val_start_day):\n",
    "    day = df['time']//1440\n",
    "    df_val = df.loc[(day>=val_start_day)].copy()\n",
    "    df = df.loc[(day<val_start_day)].copy()\n",
    "    return df, df_val\n",
    "    \n",
    "def remove_infrequent_places_df(df, th=5):\n",
    "    place_counts = df.place_id.value_counts()\n",
    "    mask = (place_counts[df.place_id.values] >= th).values\n",
    "    df = df[mask]\n",
    "    return df\n",
    "\n",
    "def prepare_data(datapath, val_start_day, train_columns, test_columns, \n",
    "                 fw, th, off):\n",
    "    val_label = None\n",
    "    print('Loading train data')\n",
    "    df_train = load_data(datapath + 'train.csv.zip')\n",
    "    if val_start_day > 0:\n",
    "        # Create validation data\n",
    "        df_train, df_test = validation_split(df_train, val_start_day)\n",
    "        val_label = df_test['place_id'] \n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)\n",
    "    print('Feature engineering on train')\n",
    "    df_train.drop(['row_id'], axis=1, inplace=True)\n",
    "    df_train = remove_infrequent_places_df(df_train, th)\n",
    "    gc.collect()\n",
    "    df_train = feature_engineering(df_train, off)\n",
    "    df_train = apply_weights(df_train, fw)\n",
    "    # reorder the columns so the place id is at the end\n",
    "    train = df_train[train_columns].values\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "    if val_start_day == 0:\n",
    "        print('Loading test data')\n",
    "        df_test = load_data(datapath + 'test.csv.zip') \n",
    "        df_sub = pd.read_csv(datapath + 'sample_submission.csv.zip', index_col = 0)\n",
    "        df_test = df_test[~df_test.index.duplicated(keep='first')]\n",
    "        df_test = df_test.loc[:df_sub.index[-1]]\n",
    "    print('Feature engineering on test')\n",
    "    df_test = feature_engineering(df_test, off)\n",
    "    df_test = apply_weights(df_test, fw)\n",
    "    test = df_test[test_columns].values\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    return train, test, val_label\n",
    "        \n",
    "def apply_weights(df, fw):\n",
    "    df['accuracy'] *= fw[0]\n",
    "    df['week_of_year_sin'] *= fw[1]\n",
    "    df['week_of_year_cos'] *= fw[1]\n",
    "    df['minute_sin'] *= fw[2]\n",
    "    df['minute_cos'] *= fw[2]\n",
    "    df['weekday_sin'] *= fw[3]\n",
    "    df['weekday_cos'] *= fw[3]\n",
    "    df.x *= fw[4]\n",
    "    df.y *= fw[5]\n",
    "    df['year'] *= fw[6]\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df, off):\n",
    "    minute =((df[\"time\"]+off[0])//5)%288\n",
    "    trig_arrays = time_trig(288)\n",
    "    df['minute_sin'] = trig_arrays[0][minute]\n",
    "    df['minute_cos'] = trig_arrays[1][minute]\n",
    "    del minute\n",
    "    week = ((df['time']+off[1])//10080)%52\n",
    "    trig_arrays = time_trig(52)\n",
    "    df['week_of_year_sin'] = trig_arrays[0][week]\n",
    "    df['week_of_year_cos'] = trig_arrays[1][week]\n",
    "    del week\n",
    "    weekday = ((df['time']+off[2])//1440)%7\n",
    "    trig_arrays = time_trig(7)\n",
    "    df['weekday_sin'] = trig_arrays[0][weekday]\n",
    "    df['weekday_cos'] = trig_arrays[1][weekday]\n",
    "    del weekday\n",
    "    df['year'] = (df['time']//525600).astype(float)\n",
    "    df.drop(['time'], axis=1, inplace=True)\n",
    "    df['accuracy'] = np.log(df['accuracy']).astype(float)\n",
    "    return df\n",
    "    \n",
    "def get_cut_list(num_cuts, dim_max, border_aug):\n",
    "    cut_list = [0]\n",
    "    cut_list.append(dim_max / num_cuts + border_aug)\n",
    "    step = ((dim_max - (dim_max / num_cuts) - border_aug) - cut_list[1]) / (num_cuts - 2)\n",
    "    for i in range(1, num_cuts - 1):\n",
    "        cut_list.append(cut_list[i] + step)\n",
    "    cut_list.append(dim_max + 1)\n",
    "    print(cut_list)\n",
    "    return cut_list\n",
    "    \n",
    "print('Starting...')\n",
    "start_time = time.time()\n",
    "# Global variables\n",
    "datapath = '../input/facebook-v-predicting-check-ins/'\n",
    "# Change val_start_day to zero to generate predictions\n",
    "val_start_day = 0 # Day at which to cut validation\n",
    "th = 5 # Threshold at which to cut places from train\n",
    "fw = [55., 32.3, 64.4, 26., 2300, 5625, 55.6]\n",
    "off = [444, 931, 421]\n",
    "\n",
    "# Defining the size of the grid\n",
    "x_cuts = 12 # number of cuts along x \n",
    "y_cuts = 25 # number of cuts along y\n",
    "#TODO: More general solution for t_cuts. For now must be 4.\n",
    "t_cuts = 4 # number of cuts along time. \n",
    "x_border_aug = 0.0055 * fw[4] # expansion of x border on train \n",
    "y_border_aug = 0.0045 * fw[5] # expansion of y border on train\n",
    "time_aug = 3\n",
    "n_neighbors = 0\n",
    "columns = ['x', 'y', 'minute_sin', 'minute_cos', 'accuracy',\n",
    "           'week_of_year_sin', 'week_of_year_cos', \n",
    "           'weekday_sin', 'weekday_cos', 'year']\n",
    "train_columns = columns + ['place_id']\n",
    "test_columns  = columns + ['row_id']\n",
    "\n",
    "train, test, val_label = prepare_data(datapath, val_start_day,\n",
    "                                      train_columns, test_columns, fw, th, off)\n",
    "\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Data prepared in:', timedelta(seconds=elapsed))\n",
    "\n",
    "x_cut_list = get_cut_list(x_cuts, train[:, 0].max(), x_border_aug)\n",
    "y_cut_list = get_cut_list(y_cuts, train[:, 1].max(), y_border_aug)\n",
    "\n",
    "preds = process_grid(train, test, x_cut_list, y_cut_list, t_cuts,\n",
    "                     x_border_aug, y_border_aug, time_aug, \n",
    "                     fw, th, n_neighbors)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Predictions made in:', timedelta(seconds=elapsed))\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    print('Pred shape:', preds.shape)\n",
    "    generate_submission(preds)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Task completed in:', timedelta(seconds=elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb260cf",
   "metadata": {
    "papermill": {
     "duration": 0.008235,
     "end_time": "2021-07-08T03:01:25.920665",
     "exception": false,
     "start_time": "2021-07-08T03:01:25.912430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1081.033587,
   "end_time": "2021-07-08T03:01:27.839578",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-08T02:43:26.805991",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
